{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5700246,"sourceType":"datasetVersion","datasetId":3277799},{"sourceId":85789536,"sourceType":"kernelVersion"}],"dockerImageVersionId":30498,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport matplotlib.pyplot as plt \nfrom tqdm import tqdm\nimport cv2\nimport os\nimport seaborn as sns\nimport tensorflow as tf\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Flatten, Conv2D, Reshape, Input, Conv2DTranspose\nfrom keras.layers import Activation, LeakyReLU, BatchNormalization, Dropout, Resizing\nfrom keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.applications import VGG16\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ntry:\n    from tensorflow.keras.optimizers.legacy import Adam\nexcept ImportError:\n    from keras.optimizers import Adam","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:32:26.696127Z","iopub.execute_input":"2025-02-25T15:32:26.697083Z","iopub.status.idle":"2025-02-25T15:32:35.053315Z","shell.execute_reply.started":"2025-02-25T15:32:26.697043Z","shell.execute_reply":"2025-02-25T15:32:35.052609Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"NOISE_DIM = 150 \nBATCH_SIZE = 16\nSTEPS_PER_EPOCH = 1000\nEPOCHS = 10\nSEED = 40\nWIDTH, HEIGHT, CHANNELS = 128, 128, 3\n\n\nOPTIMIZER = Adam(0.0002, 0.5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:32:35.054964Z","iopub.execute_input":"2025-02-25T15:32:35.056161Z","iopub.status.idle":"2025-02-25T15:32:35.072145Z","shell.execute_reply.started":"2025-02-25T15:32:35.056128Z","shell.execute_reply":"2025-02-25T15:32:35.071470Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#MAIN_DIR = \"../input/brain-mri-images-for-brain-tumor-detection/yes\"\nMAIN_DIR = \"../input/pc-data-dataset-gen\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:32:43.489533Z","iopub.execute_input":"2025-02-25T15:32:43.490472Z","iopub.status.idle":"2025-02-25T15:32:43.494230Z","shell.execute_reply.started":"2025-02-25T15:32:43.490438Z","shell.execute_reply":"2025-02-25T15:32:43.493325Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Loading and Preprocessing the Images\ndef load_images(folder):\n    \n    imgs = []\n    target = 1\n    labels = []\n    for i in os.listdir(folder):\n        img_dir = os.path.join(folder,i)\n        try:\n            img = cv2.imread(img_dir)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n            img = cv2.resize(img, (128,128))\n            imgs.append(img)\n            labels.append(target)\n        except:\n            continue\n        \n    imgs = np.array(imgs)\n    labels = np.array(labels)\n    \n    return imgs, labels\n","metadata":{"execution":{"iopub.status.busy":"2025-02-25T15:32:45.930396Z","iopub.execute_input":"2025-02-25T15:32:45.931150Z","iopub.status.idle":"2025-02-25T15:32:45.937624Z","shell.execute_reply.started":"2025-02-25T15:32:45.931117Z","shell.execute_reply":"2025-02-25T15:32:45.936587Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import zipfile","metadata":{"execution":{"iopub.status.busy":"2025-02-25T15:32:50.493831Z","iopub.execute_input":"2025-02-25T15:32:50.494168Z","iopub.status.idle":"2025-02-25T15:32:50.498588Z","shell.execute_reply.started":"2025-02-25T15:32:50.494141Z","shell.execute_reply":"2025-02-25T15:32:50.497558Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"data, labels = load_images(MAIN_DIR)\ndata.shape, labels.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:32:52.621475Z","iopub.execute_input":"2025-02-25T15:32:52.621866Z","iopub.status.idle":"2025-02-25T15:32:52.760272Z","shell.execute_reply.started":"2025-02-25T15:32:52.621842Z","shell.execute_reply":"2025-02-25T15:32:52.759177Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"((0,), (0,))"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:32:55.858926Z","iopub.execute_input":"2025-02-25T15:32:55.859382Z","iopub.status.idle":"2025-02-25T15:32:55.865177Z","shell.execute_reply.started":"2025-02-25T15:32:55.859349Z","shell.execute_reply":"2025-02-25T15:32:55.863819Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"with zipfile.ZipFile(\"../input/pc-data-dataset-gen/test.zip\",\"r\") as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"../input/pc-data-dataset-gen/train.zip\",\"r\") as z:\n    z.extractall(\".\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:33:04.270922Z","iopub.execute_input":"2025-02-25T15:33:04.271532Z","iopub.status.idle":"2025-02-25T15:33:46.916802Z","shell.execute_reply.started":"2025-02-25T15:33:04.271500Z","shell.execute_reply":"2025-02-25T15:33:46.916045Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"image_gen = ImageDataGenerator(\n                                width_shift_range=0.1,\n                                height_shift_range=0.1,\n                                rescale=1/255,\n                                shear_range=0.2,\n                                zoom_range=0.2,\n                                horizontal_flip=True,\n                                fill_mode=\"nearest\"\n                                )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:33:46.918213Z","iopub.execute_input":"2025-02-25T15:33:46.918466Z","iopub.status.idle":"2025-02-25T15:33:46.922890Z","shell.execute_reply.started":"2025-02-25T15:33:46.918444Z","shell.execute_reply":"2025-02-25T15:33:46.922054Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"batch_size = 32\ntest_image_gen = image_gen.flow_from_directory(\"./test\",\n                                                target_size=(128, 128),\n                                                batch_size=batch_size,\n                                                class_mode=\"categorical\")\ntrain_image_gen = image_gen.flow_from_directory(\"./train\",\n                                                target_size=(128, 128),\n                                                batch_size=batch_size,\n                                                class_mode=\"categorical\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T15:33:46.923948Z","iopub.execute_input":"2025-02-25T15:33:46.924222Z","iopub.status.idle":"2025-02-25T15:33:47.379630Z","shell.execute_reply.started":"2025-02-25T15:33:46.924202Z","shell.execute_reply":"2025-02-25T15:33:47.379000Z"}},"outputs":[{"name":"stdout","text":"Found 1051 images belonging to 10 classes.\nFound 8412 images belonging to 10 classes.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-22T17:38:28.851763Z","iopub.execute_input":"2025-02-22T17:38:28.852073Z","iopub.status.idle":"2025-02-22T17:51:54.150751Z","shell.execute_reply.started":"2025-02-22T17:38:28.852048Z","shell.execute_reply":"2025-02-22T17:51:54.149538Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\nclass_labels = list(test_image_gen.class_indices.keys())\n\nplt.figure(figsize=(20, 8))\nfor i in range(10):\n    axs = plt.subplot(2, 5, i + 1)\n    batch = test_image_gen.next()\n    image = batch[0][0]  # Get the first image in the batch\n    label = np.argmax(batch[1][0])  # Get the class label index\n    plt.imshow(image, cmap=\"gray\")\n    plt.title(class_labels[label])\n    plt.axis('off')\n    axs.set_xticklabels([])\n    axs.set_yticklabels([])\n    plt.subplots_adjust(wspace=None, hspace=None)\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2025-02-17T07:49:43.191497Z","iopub.execute_input":"2025-02-17T07:49:43.191714Z","iopub.status.idle":"2025-02-17T07:49:47.973948Z","shell.execute_reply.started":"2025-02-17T07:49:43.191695Z","shell.execute_reply":"2025-02-17T07:49:47.972764Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\nclass_labels = list(train_image_gen.class_indices.keys())\n\nplt.figure(figsize=(20, 8))\nfor i in range(10):\n    axs = plt.subplot(2, 5, i + 1)\n    batch = test_image_gen.next()\n    image = batch[0][0]  # Get the first image in the batch\n    label = np.argmax(batch[1][0])  # Get the class label index\n    plt.imshow(image, cmap=\"gray\")\n    plt.title(class_labels[label])\n    plt.axis('off')\n    axs.set_xticklabels([])\n    axs.set_yticklabels([])\n    plt.subplots_adjust(wspace=None, hspace=None)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T05:04:52.682429Z","iopub.execute_input":"2025-02-17T05:04:52.682792Z","iopub.status.idle":"2025-02-17T05:04:57.330108Z","shell.execute_reply.started":"2025-02-17T05:04:52.682761Z","shell.execute_reply":"2025-02-17T05:04:57.328943Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_shape = test_image_gen.image_shape\nprint(\"Image shape:\", image_shape)\nimage_shape = train_image_gen.image_shape\nprint(\"Image shape:\", image_shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T15:13:37.156130Z","iopub.execute_input":"2025-02-23T15:13:37.156409Z","iopub.status.idle":"2025-02-23T15:13:37.161053Z","shell.execute_reply.started":"2025-02-23T15:13:37.156386Z","shell.execute_reply":"2025-02-23T15:13:37.160284Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test = test_image_gen\nX_train = train_image_gen\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T15:13:37.162122Z","iopub.execute_input":"2025-02-23T15:13:37.162366Z","iopub.status.idle":"2025-02-23T15:13:37.172698Z","shell.execute_reply.started":"2025-02-23T15:13:37.162347Z","shell.execute_reply":"2025-02-23T15:13:37.171699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Generate 20 random numbers to index images from data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.random.seed(SEED)\nidxs = np.random.randint(0, 155, 20)\nprint(idxs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(os.listdir('./train'))  # Should list class subfolders inside 'train'\nprint(os.listdir('./test'))   # Should list class subfolders inside 'test'\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Number of classes in train set: {train_image_gen.num_classes}\")\nprint(f\"Number of classes in test set: {test_image_gen.num_classes}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T12:44:18.002589Z","iopub.execute_input":"2025-02-18T12:44:18.002975Z","iopub.status.idle":"2025-02-18T12:44:23.032214Z","shell.execute_reply.started":"2025-02-18T12:44:18.002945Z","shell.execute_reply":"2025-02-18T12:44:23.030852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T12:44:23.033945Z","iopub.execute_input":"2025-02-18T12:44:23.034289Z","iopub.status.idle":"2025-02-18T12:44:27.833898Z","shell.execute_reply.started":"2025-02-18T12:44:23.034260Z","shell.execute_reply":"2025-02-18T12:44:27.832049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get a single batch from the generator and check its shape\nbatch = train_image_gen.next()\nprint(\"Batch shape:\", batch[0].shape)  # Batch shape should be (batch_size, 128, 128, 3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T15:13:37.173857Z","iopub.execute_input":"2025-02-23T15:13:37.174229Z","iopub.status.idle":"2025-02-23T15:13:37.465191Z","shell.execute_reply.started":"2025-02-23T15:13:37.174202Z","shell.execute_reply":"2025-02-23T15:13:37.464272Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch = test_image_gen.next()\nprint(\"Batch shape:\", batch[0].shape)  # Batch shape should be (batch_size, 128, 128, 3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T15:13:37.466173Z","iopub.execute_input":"2025-02-23T15:13:37.466442Z","iopub.status.idle":"2025-02-23T15:13:37.746379Z","shell.execute_reply.started":"2025-02-23T15:13:37.466421Z","shell.execute_reply":"2025-02-23T15:13:37.745579Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example to fetch a batch and use it directly\nbatch = train_image_gen.next()\nX_train = batch[0]  # Images\ny_train = batch[1]  # Labels\n\n# Now you can use X_train and y_train for training or further processing\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T15:13:37.747498Z","iopub.execute_input":"2025-02-23T15:13:37.748139Z","iopub.status.idle":"2025-02-23T15:13:38.026076Z","shell.execute_reply.started":"2025-02-23T15:13:37.748109Z","shell.execute_reply":"2025-02-23T15:13:38.025462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example to fetch a batch and use it directly\nbatch = test_image_gen.next()\nX_test = batch[0]  # Images\ny_test = batch[1]  # Labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T15:13:38.027195Z","iopub.execute_input":"2025-02-23T15:13:38.027551Z","iopub.status.idle":"2025-02-23T15:13:38.312748Z","shell.execute_reply.started":"2025-02-23T15:13:38.027519Z","shell.execute_reply":"2025-02-23T15:13:38.311761Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_all = []\ny_train_all = []\n\n# Let's collect the images for one full pass through the data (one epoch)\nfor _ in range(len(train_image_gen)):\n    batch = train_image_gen.next()\n    X_train_all.append(batch[0])\n    y_train_all.append(batch[1])\n\n# Convert lists to numpy arrays\nX_train_all = np.concatenate(X_train_all)\ny_train_all = np.concatenate(y_train_all)\n\nprint(\"Shape of X_train_all:\", X_train_all.shape)\nprint(\"Shape of y_train_all:\", y_train_all.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T15:13:38.315537Z","iopub.execute_input":"2025-02-23T15:13:38.315878Z","iopub.status.idle":"2025-02-23T15:14:50.233146Z","shell.execute_reply.started":"2025-02-23T15:13:38.315845Z","shell.execute_reply":"2025-02-23T15:14:50.232235Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_all = []\ny_test_all = []\n\n# Let's collect the images for one full pass through the data (one epoch)\nfor _ in range(len(test_image_gen)):\n    batch = train_image_gen.next()\n    X_test_all.append(batch[0])\n    y_test_all.append(batch[1])\n\n# Convert lists to numpy arrays\nX_test_all = np.concatenate(X_test_all)\ny_test_all = np.concatenate(y_test_all)\n\nprint(\"Shape of X_test_all:\", X_test_all.shape)\nprint(\"Shape of y_test_all:\", y_test_all.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T15:14:50.234312Z","iopub.execute_input":"2025-02-23T15:14:50.234899Z","iopub.status.idle":"2025-02-23T15:14:59.399737Z","shell.execute_reply.started":"2025-02-23T15:14:50.234874Z","shell.execute_reply":"2025-02-23T15:14:59.398913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"NOISE_DIM = 100  \nBATCH_SIZE = 32\n\nSTEPS_PER_EPOCH = 2000\nEPOCHS = 10\nSEED = 40\nWIDTH, HEIGHT, CHANNELS = 128, 128, 1\n\nOPTIMIZER = Adam(0.0002, 0.5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T15:14:59.402024Z","iopub.execute_input":"2025-02-23T15:14:59.402708Z","iopub.status.idle":"2025-02-23T15:14:59.407639Z","shell.execute_reply.started":"2025-02-23T15:14:59.402673Z","shell.execute_reply":"2025-02-23T15:14:59.406625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Normalize and reshape all the images\nX_train = (X_train_all.astype(np.float32) - 127.5) / 127.5\nX_train = X_train.reshape(-1, WIDTH, HEIGHT, 3)  # Keep the 3 color channels for RGB\n\nprint(\"Shape of X_train after reshaping:\", X_train.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T15:14:59.408927Z","iopub.execute_input":"2025-02-23T15:14:59.409503Z","iopub.status.idle":"2025-02-23T15:15:00.282397Z","shell.execute_reply.started":"2025-02-23T15:14:59.409473Z","shell.execute_reply":"2025-02-23T15:15:00.281480Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Normalize and reshape all the images\nX_test = (X_test_all.astype(np.float32) - 127.5) / 127.5\nX_test = X_test.reshape(-1, WIDTH, HEIGHT, 3)  # Keep the 3 color channels for RGB\n\nprint(\"Shape of X_test after reshaping:\", X_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T15:15:00.283563Z","iopub.execute_input":"2025-02-23T15:15:00.283802Z","iopub.status.idle":"2025-02-23T15:15:00.395493Z","shell.execute_reply.started":"2025-02-23T15:15:00.283782Z","shell.execute_reply":"2025-02-23T15:15:00.394562Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Assuming X_train_all is your training data\n# Replace this with your actual data loading/preprocessing code\nX_train_all = np.random.randn(8412, 128, 128, 3)  # Example data\n\n# Save the training data as a NumPy array file\nnp.save('X_train_all.npy', X_train_all)\nprint(X_train_all.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T15:15:00.396694Z","iopub.execute_input":"2025-02-23T15:15:00.396948Z","iopub.status.idle":"2025-02-23T15:15:13.294993Z","shell.execute_reply.started":"2025-02-23T15:15:00.396926Z","shell.execute_reply":"2025-02-23T15:15:13.294043Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T09:31:41.365431Z","iopub.execute_input":"2025-02-23T09:31:41.365780Z","iopub.status.idle":"2025-02-23T09:40:01.738951Z","shell.execute_reply.started":"2025-02-23T09:31:41.365751Z","shell.execute_reply":"2025-02-23T09:40:01.737574Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T15:48:28.607072Z","iopub.execute_input":"2025-02-23T15:48:28.607454Z","iopub.status.idle":"2025-02-23T15:48:28.615420Z","shell.execute_reply.started":"2025-02-23T15:48:28.607424Z","shell.execute_reply":"2025-02-23T15:48:28.614203Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ['TF_DISABLE_LAYOUT_OPTIMIZER'] = '1'  # Disable layout optimizer\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Flatten, Conv2D, Reshape, Input, Conv2DTranspose, UpSampling2D\nfrom keras.layers import Activation, LeakyReLU, BatchNormalization, Dropout, Add\nfrom keras.losses import BinaryCrossentropy\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.optimizers.legacy import Adam\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom scipy.linalg import sqrtm\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# Load the training data\nX_train = np.load('X_train_all.npy')\n\n# Normalize X_train to [-1, 1]\nX_train_min, X_train_max = X_train.min(), X_train.max()\nX_train = 2 * (X_train - X_train_min) / (X_train_max - X_train_min) - 1\nprint(f\"X_train range after normalization: [{X_train.min():.2f}, {X_train.max():.2f}]\")\n\n# Set random seed for reproducibility\nnp.random.seed(40)\ntf.random.set_seed(40)\n\n# Constants\nNOISE_DIM = 150\nBATCH_SIZE = 64\nSTEPS_PER_EPOCH = 132\nEPOCHS = 50\nIMG_WIDTH, IMG_HEIGHT, CHANNELS = 128, 128, 3\nG_LR = 0.0006\nD_LR = 0.0001\n\n# Load Inception V3 for FID\ninception_model = InceptionV3(weights='imagenet', include_top=False, pooling='avg', input_shape=(299, 299, 3))\n\n# FID Calculation (unchanged)\ndef calculate_fid(real_images, generated_images):\n    real_images_resized = tf.image.resize(real_images, (299, 299))\n    gen_images_resized = tf.image.resize(generated_images, (299, 299))\n    real_images_proc = preprocess_input((real_images_resized + 1) * 127.5)\n    gen_images_proc = preprocess_input((gen_images_resized + 1) * 127.5)\n    real_features = inception_model.predict(real_images_proc, verbose=0)\n    gen_features = inception_model.predict(gen_images_proc, verbose=0)\n    mu1, sigma1 = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)\n    mu2, sigma2 = np.mean(gen_features, axis=0), np.cov(gen_features, rowvar=False)\n    diff = mu1 - mu2\n    covmean = sqrtm(sigma1.dot(sigma2))\n    if np.iscomplexobj(covmean):\n        covmean = covmean.real\n    fid = diff.dot(diff) + np.trace(sigma1 + sigma2 - 2 * covmean)\n    return fid\n\n# Enhanced Generator\ndef build_generator():\n    inputs = Input(shape=(NOISE_DIM,))\n    \n    # Initial dense layer with increased capacity\n    x = Dense(8 * 8 * 2048, input_dim=NOISE_DIM)(inputs)  # Start at 8x8 with more filters\n    x = Reshape((8, 8, 2048))(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    # Upsample to 16x16 with residual connection\n    x = UpSampling2D()(x)  # 16x16\n    shortcut = Conv2D(1024, (1,1), padding='same')(x)\n    x = Conv2D(1024, (3,3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = Add()([x, shortcut])\n    \n    # Upsample to 32x32 with transpose convolution\n    x = Conv2DTranspose(512, (4,4), strides=2, padding='same')(x)  # 32x32\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = Dropout(0.2)(x)\n    \n    # Upsample to 64x64\n    x = Conv2DTranspose(256, (4,4), strides=2, padding='same')(x)  # 64x64\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    # Upsample to 128x128\n    x = Conv2DTranspose(128, (4,4), strides=2, padding='same')(x)  # 128x128\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    # Refinement layer\n    x = Conv2D(64, (3,3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    # Output layer\n    outputs = Conv2D(CHANNELS, (3,3), padding='same', activation='tanh')(x)\n    \n    return Model(inputs, outputs)\n\n# Discriminator (unchanged)\ndef build_discriminator():\n    model = Sequential()\n    model.add(tfa.layers.SpectralNormalization(Conv2D(32, (3,3), strides=2, padding='same',\n                     input_shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS))))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.3))\n    model.add(tfa.layers.SpectralNormalization(Conv2D(64, (3,3), strides=2, padding='same')))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.3))\n    model.add(tfa.layers.SpectralNormalization(Conv2D(128, (3,3), strides=2, padding='same')))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.3))\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n    return model\n\n# Build and compile models\ndiscriminator = build_discriminator()\ndiscriminator.compile(loss='binary_crossentropy', \n                     optimizer=Adam(learning_rate=D_LR, beta_1=0.5, beta_2=0.999), \n                     metrics=['accuracy'])\n\ngenerator = build_generator()\nz = Input(shape=(NOISE_DIM,))\nimg = generator(z)\ndiscriminator.trainable = False\nvalidity = discriminator(img)\ngan = Model(z, validity)\ngan.compile(loss='binary_crossentropy', \n            optimizer=Adam(learning_rate=G_LR, beta_1=0.5, beta_2=0.999))\n\n# Training Function (increased generator updates)\ndef train_gan(epochs, batch_size, steps_per_epoch, X_train):\n    real_label_smooth = np.random.uniform(0.8, 1.0, (batch_size, 1))\n    fake_label_smooth = np.zeros((batch_size, 1)) + 0.1\n    \n    os.makedirs(\"gan_progress\", exist_ok=True)\n    d_losses, g_losses, acc_real, acc_fake, fid_scores, precisions, recalls = [], [], [], [], [], [], []\n    \n    for epoch in range(epochs):\n        epoch_d_loss, epoch_g_loss, epoch_acc_real, epoch_acc_fake = [], [], [], []\n        progress_bar = tqdm(range(steps_per_epoch), desc=f\"Epoch {epoch+1}/{epochs}\")\n        \n        for step in progress_bar:\n            # Train Generator (3 updates for more power)\n            for _ in range(3):\n                noise = np.random.normal(0, 1, (batch_size, NOISE_DIM))\n                g_loss = gan.train_on_batch(noise, real_label_smooth)\n            \n            # Train Discriminator\n            idx = np.random.randint(0, X_train.shape[0], batch_size)\n            real_imgs = X_train[idx]\n            fake_imgs = generator.predict(noise, verbose=0)\n            \n            real_preds = discriminator.predict(real_imgs, verbose=0)\n            fake_preds = discriminator.predict(fake_imgs, verbose=0)\n            acc_r = np.mean(real_preds)\n            acc_f = np.mean(fake_preds)\n            \n            d_loss = 0\n            if step % 3 == 0 or acc_r > 0.9:\n                d_loss_real = discriminator.train_on_batch(real_imgs, real_label_smooth)[0]\n                d_loss_fake = discriminator.train_on_batch(fake_imgs, fake_label_smooth)[0]\n                d_loss = 0.5 * (d_loss_real + d_loss_fake)\n            \n            acc_r_display = acc_r * 100\n            acc_f_display = (1 - acc_f) * 100\n            \n            epoch_d_loss.append(d_loss)\n            epoch_g_loss.append(g_loss)\n            epoch_acc_real.append(acc_r_display)\n            epoch_acc_fake.append(acc_f_display)\n            \n            progress_bar.set_postfix({\n                'D Loss': f\"{d_loss:.4f}\",\n                'G Loss': f\"{g_loss:.4f}\",\n                'Acc Real': f\"{acc_r_display:.2f}%\",\n                'Acc Fake': f\"{acc_f_display:.2f}%\"\n            })\n        \n        # Compute averages\n        avg_d_loss = np.mean([x for x in epoch_d_loss if x != 0])\n        avg_g_loss = np.mean(epoch_g_loss)\n        avg_acc_r = np.mean(epoch_acc_real)\n        avg_acc_f = np.mean(epoch_acc_fake)\n        \n        # Calculate FID\n        noise = np.random.normal(0, 1, (batch_size, NOISE_DIM))\n        gen_imgs = generator.predict(noise, verbose=0)\n        fid = calculate_fid(real_imgs, gen_imgs)\n        \n        # Calculate Precision and Recall\n        real_labels = np.ones(batch_size)\n        fake_labels = np.zeros(batch_size)\n        all_labels = np.concatenate([real_labels, fake_labels])\n        all_preds = np.concatenate([real_preds, fake_preds]) > 0.5\n        precision = precision_score(all_labels, all_preds)\n        recall = recall_score(all_labels, all_preds)\n        \n        d_losses.append(avg_d_loss)\n        g_losses.append(avg_g_loss)\n        acc_real.append(avg_acc_r)\n        acc_fake.append(avg_acc_f)\n        fid_scores.append(fid)\n        precisions.append(precision * 100)\n        recalls.append(recall * 100)\n        \n        print(f\"\\nEpoch {epoch+1} Summary:\")\n        print(f\"  Discriminator Loss: {avg_d_loss:.4f}\")\n        print(f\"  Generator Loss: {avg_g_loss:.4f}\")\n        print(f\"  Real Image Accuracy: {avg_acc_r:.2f}%\")\n        print(f\"  Fake Image Accuracy: {avg_acc_f:.2f}%\")\n        print(f\"  FID Score: {fid:.2f}\")\n        print(f\"  Precision: {precision*100:.2f}%\")\n        print(f\"  Recall: {recall*100:.2f}\\n\")\n        \n        generate_images(epoch)\n        if epoch % 5 == 0:\n            plot_metrics(d_losses, g_losses, acc_real, acc_fake, fid_scores, precisions, recalls)\n    \n    return d_losses, g_losses, acc_real, acc_fake, fid_scores, precisions, recalls\n\n# Visualization Functions (unchanged)\ndef plot_metrics(d_losses, g_losses, acc_real, acc_fake, fid_scores, precisions, recalls):\n    plt.figure(figsize=(15, 10))\n    plt.subplot(2, 2, 1)\n    plt.plot(d_losses, label='Discriminator Loss')\n    plt.plot(g_losses, label='Generator Loss')\n    plt.title(\"Training Losses\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.subplot(2, 2, 2)\n    plt.plot(acc_real, label='Real Accuracy')\n    plt.plot(acc_fake, label='Fake Accuracy')\n    plt.title(\"Classification Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy (%)\")\n    plt.legend()\n    plt.subplot(2, 2, 3)\n    plt.plot(fid_scores, label='FID Score')\n    plt.title(\"Fréchet Inception Distance\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"FID\")\n    plt.legend()\n    plt.subplot(2, 2, 4)\n    plt.plot(precisions, label='Precision')\n    plt.plot(recalls, label='Recall')\n    plt.title(\"Precision and Recall\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Percentage (%)\")\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\ndef generate_images(epoch, num_images=9):\n    noise = np.random.normal(0, 1, (num_images, NOISE_DIM))\n    gen_imgs = generator.predict(noise, verbose=0)\n    gen_imgs = 0.5 * gen_imgs + 0.5  # Rescale to [0, 1] for visualization\n    gen_imgs = (gen_imgs * 255).astype(np.uint8)\n    plt.figure(figsize=(10, 10))\n    for i in range(num_images):\n        plt.subplot(3, 3, i+1)\n        plt.imshow(gen_imgs[i])\n        plt.axis('off')\n    plt.suptitle(f\"Epoch {epoch+1}\", fontsize=20)\n    plt.savefig(f\"gan_progress/epoch_{epoch+1}.png\")\n    plt.show()\n    plt.close()\n\n# Training Execution\nhistory = train_gan(epochs=EPOCHS, \n                    batch_size=BATCH_SIZE, \n                    steps_per_epoch=STEPS_PER_EPOCH, \n                    X_train=X_train)\n\n# Save models\ngenerator.save('generator_model.h5')\ndiscriminator.save('discriminator_model.h5')\n\ngan.save('gan_model.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T15:48:39.903003Z","iopub.execute_input":"2025-02-23T15:48:39.903355Z","iopub.status.idle":"2025-02-23T16:09:14.630620Z","shell.execute_reply.started":"2025-02-23T15:48:39.903327Z","shell.execute_reply":"2025-02-23T16:09:14.629118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Enhanced Generator\ndef build_generator():\n    inputs = Input(shape=(NOISE_DIM,))\n    \n    # Initial dense layer with increased capacity\n    x = Dense(8 * 8 * 2048, input_dim=NOISE_DIM)(inputs)  # Start at 8x8 with more filters\n    x = Reshape((8, 8, 2048))(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    # Upsample to 16x16 with residual connection\n    x = UpSampling2D()(x)  # 16x16\n    shortcut = Conv2D(1024, (1,1), padding='same')(x)\n    x = Conv2D(1024, (3,3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = Add()([x, shortcut])\n    \n    # Upsample to 32x32 with transpose convolution\n    x = Conv2DTranspose(512, (4,4), strides=2, padding='same')(x)  # 32x32\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = Dropout(0.2)(x)\n    \n    # Upsample to 64x64\n    x = Conv2DTranspose(256, (4,4), strides=2, padding='same')(x)  # 64x64\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    # Upsample to 128x128\n    x = Conv2DTranspose(128, (4,4), strides=2, padding='same')(x)  # 128x128\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    # Refinement layer\n    x = Conv2D(64, (3,3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    # Output layer\n    outputs = Conv2D(CHANNELS, (3,3), padding='same', activation='tanh')(x)\n    \n    return Model(inputs, outputs)\n\n# Discriminator (unchanged)\ndef build_discriminator():\n    model = Sequential()\n    model.add(tfa.layers.SpectralNormalization(Conv2D(32, (3,3), strides=2, padding='same',\n                     input_shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS))))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.3))\n    model.add(tfa.layers.SpectralNormalization(Conv2D(64, (3,3), strides=2, padding='same')))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.3))\n    model.add(tfa.layers.SpectralNormalization(Conv2D(128, (3,3), strides=2, padding='same')))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.3))\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n    return model\n\n# Build and compile models\ndiscriminator = build_discriminator()\ndiscriminator.compile(loss='binary_crossentropy', \n                     optimizer=Adam(learning_rate=D_LR, beta_1=0.5, beta_2=0.999), \n                     metrics=['accuracy'])\n\ngenerator = build_generator()\nz = Input(shape=(NOISE_DIM,))\nimg = generator(z)\ndiscriminator.trainable = False\nvalidity = discriminator(img)\ngan = Model(z, validity)\ngan.compile(loss='binary_crossentropy', \n            optimizer=Adam(learning_rate=G_LR, beta_1=0.5, beta_2=0.999))\ngan.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:00:00.890606Z","iopub.execute_input":"2025-02-25T16:00:00.890969Z","iopub.status.idle":"2025-02-25T16:00:01.250130Z","shell.execute_reply.started":"2025-02-25T16:00:00.890942Z","shell.execute_reply":"2025-02-25T16:00:01.249247Z"}},"outputs":[{"name":"stdout","text":"Model: \"model_7\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_8 (InputLayer)        [(None, 150)]             0         \n                                                                 \n model_6 (Functional)        (None, 128, 128, 3)       51868035  \n                                                                 \n sequential_5 (Sequential)   (None, 1)                 126241    \n                                                                 \n=================================================================\nTotal params: 51,994,276\nTrainable params: 51,859,971\nNon-trainable params: 134,305\n_________________________________________________________________\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"er porer ta optional just chaile run koraite paris \n","metadata":{}},{"cell_type":"code","source":"import os\nos.environ['TF_DISABLE_LAYOUT_OPTIMIZER'] = '1'  # Disable layout optimizer\n\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Flatten, Conv2D, Reshape, Input, Conv2DTranspose, UpSampling2D\nfrom keras.layers import Activation, LeakyReLU, BatchNormalization, Dropout, Add\nfrom keras.losses import BinaryCrossentropy\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.optimizers.legacy import Adam\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom scipy.linalg import sqrtm\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# Load the training data\nX_train = np.load('X_train_all.npy')\n\n# Normalize X_train to [-1, 1]\nX_train_min, X_train_max = X_train.min(), X_train.max()  # Fixed syntax\nX_train = 2 * (X_train - X_train_min) / (X_train_max - X_train_min) - 1\nprint(f\"X_train range after normalization: [{X_train.min():.2f}, {X_train.max():.2f}]\")\n\n# Set random seed for reproducibility\nnp.random.seed(40)\ntf.random.set_seed(40)\n\n# Constants\nNOISE_DIM = 150\nBATCH_SIZE = 64\nSTEPS_PER_EPOCH = 50\nEPOCHS = 50\nIMG_WIDTH, IMG_HEIGHT, CHANNELS = 128, 128, 3\nG_LR = 0.0006\nD_LR = 0.00015\nEARLY_STOPPING_PATIENCE = 10\nEARLY_STOPPING_MIN_DELTA = 1.0\n\n# Load Inception V3 for FID\ninception_model = InceptionV3(weights='imagenet', include_top=False, pooling='avg', input_shape=(299, 299, 3))\n\n# FID Calculation\ndef calculate_fid(real_images, generated_images):\n    real_images_resized = tf.image.resize(real_images, (299, 299))\n    gen_images_resized = tf.image.resize(generated_images, (299, 299))\n    real_images_proc = preprocess_input((real_images_resized + 1) * 127.5)\n    gen_images_proc = preprocess_input((gen_images_resized + 1) * 127.5)\n    real_features = inception_model.predict(real_images_proc, verbose=0)\n    gen_features = inception_model.predict(gen_images_proc, verbose=0)\n    mu1, sigma1 = np.mean(real_features, axis=0), np.cov(real_features, rowvar=False)\n    mu2, sigma2 = np.mean(gen_features, axis=0), np.cov(gen_features, rowvar=False)\n    diff = mu1 - mu2\n    covmean = sqrtm(sigma1.dot(sigma2))\n    if np.iscomplexobj(covmean):\n        covmean = covmean.real\n    fid = diff.dot(diff) + np.trace(sigma1 + sigma2 - 2 * covmean)\n    return fid\n\n# Simplified Generator\ndef build_generator():\n    inputs = Input(shape=(NOISE_DIM,))\n    \n    x = Dense(8 * 8 * 2048)(inputs)\n    x = Reshape((8, 8, 2048))(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    x = UpSampling2D()(x)  # 16x16\n    shortcut = Conv2D(1024, (1,1), padding='same')(x)\n    x = Conv2D(1024, (3,3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = Add()([x, shortcut])\n    \n    x = Conv2DTranspose(512, (4,4), strides=2, padding='same')(x)  # 32x32\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = Dropout(0.2)(x)\n    \n    x = Conv2DTranspose(256, (4,4), strides=2, padding='same')(x)  # 64x64\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    x = Conv2DTranspose(128, (4,4), strides=2, padding='same')(x)  # 128x128\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    outputs = Conv2D(CHANNELS, (3,3), padding='same', activation='tanh')(x)\n    \n    return Model(inputs, outputs)\n\n# Discriminator\ndef build_discriminator():\n    model = Sequential()\n    model.add(tfa.layers.SpectralNormalization(Conv2D(32, (3,3), strides=2, padding='same',\n                     input_shape=(IMG_WIDTH, IMG_HEIGHT, CHANNELS))))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.3))\n    model.add(tfa.layers.SpectralNormalization(Conv2D(64, (3,3), strides=2, padding='same')))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.3))\n    model.add(tfa.layers.SpectralNormalization(Conv2D(128, (3,3), strides=2, padding='same')))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.3))\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n    return model\n\n# Build and compile models\ndiscriminator = build_discriminator()\ndiscriminator.compile(loss='binary_crossentropy', \n                     optimizer=Adam(learning_rate=D_LR, beta_1=0.5, beta_2=0.999), \n                     metrics=['accuracy'])\n\ngenerator = build_generator()\nz = Input(shape=(NOISE_DIM,))\nimg = generator(z)\ndiscriminator.trainable = False\nvalidity = discriminator(img)\ngan = Model(z, validity)\ngan.compile(loss='binary_crossentropy', \n            optimizer=Adam(learning_rate=G_LR, beta_1=0.5, beta_2=0.999))\n\n# Training Function with Optimizations\ndef train_gan(epochs, batch_size, steps_per_epoch, X_train):\n    real_label_smooth = np.random.uniform(0.9, 1.0, (batch_size, 1))\n    fake_label_smooth = np.zeros((batch_size, 1)) + 0.1\n    \n    os.makedirs(\"gan_progress\", exist_ok=True)\n    d_losses, g_losses, acc_real, acc_fake, fid_scores, precisions, recalls = [], [], [], [], [], [], []\n    \n    best_fid = float('inf')\n    patience_counter = 0\n    best_generator_weights = None\n    \n    for epoch in range(epochs):\n        epoch_d_loss, epoch_g_loss, epoch_acc_real, epoch_acc_fake = [], [], [], []\n        progress_bar = tqdm(range(steps_per_epoch), desc=f\"Epoch {epoch+1}/{epochs}\")\n        \n        for step in progress_bar:\n            # Train Generator (2 updates)\n            for _ in range(2):\n                noise = np.random.normal(0, 1, (batch_size, NOISE_DIM))\n                g_loss = gan.train_on_batch(noise, real_label_smooth)\n            \n            # Train Discriminator\n            idx = np.random.randint(0, X_train.shape[0], batch_size)\n            real_imgs = X_train[idx]\n            fake_imgs = generator.predict(noise, verbose=0)\n            \n            real_preds = discriminator.predict(real_imgs, verbose=0)\n            fake_preds = discriminator.predict(fake_imgs, verbose=0)\n            acc_r = np.mean(real_preds)\n            acc_f = np.mean(fake_preds)\n            \n            d_loss = 0\n            if step % 2 == 0 or acc_r > 0.9:\n                d_loss_real = discriminator.train_on_batch(real_imgs, real_label_smooth)[0]\n                d_loss_fake = discriminator.train_on_batch(fake_imgs, fake_label_smooth)[0]\n                d_loss = 0.5 * (d_loss_real + d_loss_fake)\n            \n            acc_r_display = acc_r * 100\n            acc_f_display = (1 - acc_f) * 100\n            \n            epoch_d_loss.append(d_loss)\n            epoch_g_loss.append(g_loss)\n            epoch_acc_real.append(acc_r_display)\n            epoch_acc_fake.append(acc_f_display)\n            \n            progress_bar.set_postfix({\n                'D Loss': f\"{d_loss:.4f}\",\n                'G Loss': f\"{g_loss:.4f}\",\n                'Acc Real': f\"{acc_r_display:.2f}%\",\n                'Acc Fake': f\"{acc_f_display:.2f}%\"\n            })\n        \n        # Compute averages\n        avg_d_loss = np.mean([x for x in epoch_d_loss if x != 0])\n        avg_g_loss = np.mean(epoch_g_loss)\n        avg_acc_r = np.mean(epoch_acc_real)\n        avg_acc_f = np.mean(epoch_acc_fake)\n        \n        # Calculate FID every 5 epochs or at stopping\n        fid = None\n        if epoch % 5 == 0 or epoch == epochs - 1 or patience_counter == EARLY_STOPPING_PATIENCE - 1:\n            noise = np.random.normal(0, 1, (batch_size, NOISE_DIM))\n            gen_imgs = generator.predict(noise, verbose=0)\n            fid = calculate_fid(real_imgs, gen_imgs)\n            fid_scores.append(fid)\n        else:\n            fid_scores.append(fid_scores[-1] if fid_scores else None)\n        \n        # Calculate Precision and Recall\n        real_labels = np.ones(batch_size)\n        fake_labels = np.zeros(batch_size)\n        all_labels = np.concatenate([real_labels, fake_labels])\n        all_preds = np.concatenate([real_preds, fake_preds]) > 0.5\n        precision = precision_score(all_labels, all_preds)\n        recall = recall_score(all_labels, all_preds)\n        \n        d_losses.append(avg_d_loss)\n        g_losses.append(avg_g_loss)\n        acc_real.append(avg_acc_r)\n        acc_fake.append(avg_acc_f)\n        precisions.append(precision * 100)\n        recalls.append(recall * 100)\n        \n        print(f\"\\nEpoch {epoch+1} Summary:\")\n        print(f\"  Discriminator Loss: {avg_d_loss:.4f}\")\n        print(f\"  Generator Loss: {avg_g_loss:.4f}\")\n        print(f\"  Real Image Accuracy: {avg_acc_r:.2f}%\")\n        print(f\"  Fake Image Accuracy: {avg_acc_f:.2f}%\")\n        print(f\"  FID Score: {fid if fid is not None else 'N/A'}\")\n        print(f\"  Precision: {precision*100:.2f}%\")\n        print(f\"  Recall: {recall*100:.2f}\")\n        print(f\"  Patience Counter: {patience_counter}/{EARLY_STOPPING_PATIENCE}\\n\")\n        \n        # Early stopping logic\n        if fid is not None:\n            if fid < best_fid - EARLY_STOPPING_MIN_DELTA:\n                best_fid = fid\n                patience_counter = 0\n                best_generator_weights = generator.get_weights()\n                print(f\"New best FID: {best_fid:.2f}, weights saved.\")\n            else:\n                patience_counter += 1\n                print(f\"No improvement in FID. Best FID remains {best_fid:.2f}.\")\n            \n            if patience_counter >= EARLY_STOPPING_PATIENCE:\n                print(f\"Early stopping triggered after {epoch+1} epochs. Restoring best weights.\")\n                generator.set_weights(best_generator_weights)\n                break\n        \n        generate_images(epoch)\n        if epoch % 5 == 0:\n            plot_metrics(d_losses, g_losses, acc_real, acc_fake, fid_scores, precisions, recalls)\n    \n    return d_losses, g_losses, acc_real, acc_fake, fid_scores, precisions, recalls\n\n# Visualization Functions\ndef plot_metrics(d_losses, g_losses, acc_real, acc_fake, fid_scores, precisions, recalls):\n    plt.figure(figsize=(15, 10))\n    plt.subplot(2, 2, 1)\n    plt.plot(d_losses, label='Discriminator Loss')\n    plt.plot(g_losses, label='Generator Loss')\n    plt.title(\"Training Losses\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.subplot(2, 2, 2)\n    plt.plot(acc_real, label='Real Accuracy')\n    plt.plot(acc_fake, label='Fake Accuracy')\n    plt.title(\"Classification Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Accuracy (%)\")\n    plt.legend()\n    plt.subplot(2, 2, 3)\n    plt.plot([f for f in fid_scores if f is not None], label='FID Score')\n    plt.title(\"Fréchet Inception Distance\")\n    plt.xlabel(\"Epoch (every 5)\")\n    plt.ylabel(\"FID\")\n    plt.legend()\n    plt.subplot(2, 2, 4)\n    plt.plot(precisions, label='Precision')\n    plt.plot(recalls, label='Recall')\n    plt.title(\"Precision and Recall\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Percentage (%)\")\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\ndef generate_images(epoch, num_images=9):\n    noise = np.random.normal(0, 1, (num_images, NOISE_DIM))\n    gen_imgs = generator.predict(noise, verbose=0)\n    gen_imgs = 0.5 * gen_imgs + 0.5\n    gen_imgs = (gen_imgs * 255).astype(np.uint8)\n    plt.figure(figsize=(10, 10))\n    for i in range(num_images):\n        plt.subplot(3, 3, i+1)\n        plt.imshow(gen_imgs[i])\n        plt.axis('off')\n    plt.suptitle(f\"Epoch {epoch+1}\", fontsize=20)\n    plt.savefig(f\"gan_progress/epoch_{epoch+1}.png\")\n    plt.show()\n    plt.close()\n\n# Training Execution\nhistory = train_gan(epochs=EPOCHS, \n                    batch_size=BATCH_SIZE, \n                    steps_per_epoch=STEPS_PER_EPOCH, \n                    X_train=X_train)\n\n# Save final models\ngenerator.save('generator_model_final.h5')\ndiscriminator.save('discriminator_model_final.h5')\ngan.save('gan_model_final.h5')\n\n# Save best model (based on FID)\ngenerator.save('generator_model_best.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-23T18:33:14.987535Z","iopub.execute_input":"2025-02-23T18:33:14.987872Z"}},"outputs":[],"execution_count":null}]}